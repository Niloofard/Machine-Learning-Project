{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GWVjvYZsQkJv",
        "outputId": "858c7944-9cd6-4c94-bd85-9cbc2c7342a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Nov 21 02:50:41 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch==2.5.0 torchvision==0.20.0 torchaudio==2.5.0 --index-url https://download.pytorch.org/whl/cu124"
      ],
      "metadata": {
        "id": "GYldV-JE8s7f",
        "outputId": "321b8424-a3a7-4e5e-8a1b-a3303bd00fcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
            "Collecting torch==2.5.0\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torch-2.5.0%2Bcu124-cp312-cp312-linux_x86_64.whl (908.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.2/908.2 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.20.0\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torchvision-0.20.0%2Bcu124-cp312-cp312-linux_x86_64.whl (7.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m100.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.5.0\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torchaudio-2.5.0%2Bcu124-cp312-cp312-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.5.0) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.0) (4.15.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.5.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.5.0) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m104.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.5.147 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.21.5 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.4.127 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m119.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.1.0 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.6/209.6 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.5.0) (75.2.0)\n",
            "Collecting sympy==1.13.1 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m119.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision==0.20.0) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision==0.20.0) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch==2.5.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.5.0) (3.0.3)\n",
            "Installing collected packages: triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.4.0\n",
            "    Uninstalling triton-3.4.0:\n",
            "      Successfully uninstalled triton-3.4.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.3\n",
            "    Uninstalling sympy-1.13.3:\n",
            "      Successfully uninstalled sympy-1.13.3\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.8.0+cu126\n",
            "    Uninstalling torch-2.8.0+cu126:\n",
            "      Successfully uninstalled torch-2.8.0+cu126\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.23.0+cu126\n",
            "    Uninstalling torchvision-0.23.0+cu126:\n",
            "      Successfully uninstalled torchvision-0.23.0+cu126\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.8.0+cu126\n",
            "    Uninstalling torchaudio-2.8.0+cu126:\n",
            "      Successfully uninstalled torchaudio-2.8.0+cu126\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 sympy-1.13.1 torch-2.5.0+cu124 torchaudio-2.5.0+cu124 torchvision-0.20.0+cu124 triton-3.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install natten==0.17.3+torch250cu124 -f https://shi-labs.com/natten/wheels/"
      ],
      "metadata": {
        "id": "sSx_WBGT8wMe",
        "outputId": "c1880992-088b-44d2-a12c-80a2dc9f5ec6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://shi-labs.com/natten/wheels/\n",
            "Collecting natten==0.17.3+torch250cu124\n",
            "  Downloading https://shi-labs.com/natten/wheels/cu124/torch2.5.0/natten-0.17.3%2Btorch250cu124-cp312-cp312-linux_x86_64.whl (474.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.5/474.5 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from natten==0.17.3+torch250cu124) (25.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from natten==0.17.3+torch250cu124) (2.5.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->natten==0.17.3+torch250cu124) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->natten==0.17.3+torch250cu124) (4.15.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->natten==0.17.3+torch250cu124) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->natten==0.17.3+torch250cu124) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->natten==0.17.3+torch250cu124) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->natten==0.17.3+torch250cu124) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->natten==0.17.3+torch250cu124) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->natten==0.17.3+torch250cu124) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->natten==0.17.3+torch250cu124) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->natten==0.17.3+torch250cu124) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->natten==0.17.3+torch250cu124) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->natten==0.17.3+torch250cu124) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->natten==0.17.3+torch250cu124) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->natten==0.17.3+torch250cu124) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->natten==0.17.3+torch250cu124) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->natten==0.17.3+torch250cu124) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->natten==0.17.3+torch250cu124) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->natten==0.17.3+torch250cu124) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->natten==0.17.3+torch250cu124) (75.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->natten==0.17.3+torch250cu124) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch>=2.0.0->natten==0.17.3+torch250cu124) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->natten==0.17.3+torch250cu124) (3.0.3)\n",
            "Installing collected packages: natten\n",
            "Successfully installed natten-0.17.3+torch250cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get started, clone the repository and navigate to the project directory:"
      ],
      "metadata": {
        "id": "IsRIXm8dS2sv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git https://github.com/Niloofard/Machine-Learning-Project.git\n",
        "%cd /content/Machine-Learning-Project"
      ],
      "metadata": {
        "id": "ufa7cY1qQ0G7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "BvriJR9GQ-DW",
        "outputId": "16bb9971-7e97-48f1-f066-e20af66be26e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (0.8.1)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (1.0.22)\n",
            "Collecting medmnist==3.0.2 (from -r requirements.txt (line 3))\n",
            "  Downloading medmnist-3.0.2-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (1.6.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (0.25.2)\n",
            "Collecting fvcore (from -r requirements.txt (line 8))\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (4.67.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (11.3.0)\n",
            "Collecting fire (from -r requirements.txt (line 11))\n",
            "  Downloading fire-0.7.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting torchattacks (from -r requirements.txt (line 12))\n",
            "  Downloading torchattacks-3.5.1-py3-none-any.whl.metadata (927 bytes)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 13)) (2.5.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 14)) (0.20.0+cu124)\n",
            "Collecting grad-cam (from -r requirements.txt (line 15))\n",
            "  Downloading grad-cam-1.5.5.tar.gz (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 16)) (1.5.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from timm->-r requirements.txt (line 2)) (6.0.3)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm->-r requirements.txt (line 2)) (0.36.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm->-r requirements.txt (line 2)) (0.6.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 5)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 5)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 5)) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 6)) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 6)) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 6)) (3.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image->-r requirements.txt (line 7)) (3.5)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image->-r requirements.txt (line 7)) (2.37.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image->-r requirements.txt (line 7)) (2025.10.16)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image->-r requirements.txt (line 7)) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->-r requirements.txt (line 7)) (0.4)\n",
            "Collecting yacs>=0.1.6 (from fvcore->-r requirements.txt (line 8))\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.12/dist-packages (from fvcore->-r requirements.txt (line 8)) (3.2.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from fvcore->-r requirements.txt (line 8)) (0.9.0)\n",
            "Collecting iopath>=0.1.7 (from fvcore->-r requirements.txt (line 8))\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting requests~=2.25.1 (from torchattacks->-r requirements.txt (line 12))\n",
            "  Downloading requests-2.25.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 13)) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 13)) (4.15.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 13)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 13)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 13)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 13)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 13)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 13)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 13)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 13)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 13)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 13)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 13)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 13)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 13)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 13)) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 13)) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 13)) (75.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 13)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 13)) (1.3.0)\n",
            "Collecting ttach (from grad-cam->-r requirements.txt (line 15))\n",
            "  Downloading ttach-0.0.3-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from grad-cam->-r requirements.txt (line 15)) (4.12.0.88)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from grad-cam->-r requirements.txt (line 15)) (3.10.0)\n",
            "Collecting portalocker (from iopath>=0.1.7->fvcore->-r requirements.txt (line 8))\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 5)) (1.17.0)\n",
            "Collecting chardet<5,>=3.0.2 (from requests~=2.25.1->torchattacks->-r requirements.txt (line 12))\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting idna<3,>=2.5 (from requests~=2.25.1->torchattacks->-r requirements.txt (line 12))\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\n",
            "Collecting urllib3<1.27,>=1.21.1 (from requests~=2.25.1->torchattacks->-r requirements.txt (line 12))\n",
            "  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests~=2.25.1->torchattacks->-r requirements.txt (line 12)) (2025.10.5)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm->-r requirements.txt (line 2)) (1.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->-r requirements.txt (line 13)) (3.0.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->grad-cam->-r requirements.txt (line 15)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->grad-cam->-r requirements.txt (line 15)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->grad-cam->-r requirements.txt (line 15)) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->grad-cam->-r requirements.txt (line 15)) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->grad-cam->-r requirements.txt (line 15)) (3.2.5)\n",
            "Downloading medmnist-3.0.2-py3-none-any.whl (25 kB)\n",
            "Downloading fire-0.7.1-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.9/115.9 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchattacks-3.5.1-py3-none-any.whl (142 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.0/142.0 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading ttach-0.0.3-py3-none-any.whl (9.8 kB)\n",
            "Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Building wheels for collected packages: fvcore, grad-cam, iopath\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61397 sha256=1fa55ec868052089354731ce3c14c18837e9ebdc30780e0dac1588eca8c713e1\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/9f/a5/e4f5b27454ccd4596bd8b62432c7d6b1ca9fa22aef9d70a16a\n",
            "  Building wheel for grad-cam (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for grad-cam: filename=grad_cam-1.5.5-py3-none-any.whl size=44284 sha256=96fe2030a70340d0411752d7664afee0d20ee052ce0f3de0774e64236e128e6a\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/3b/09/2afc520f3d69bc26ae6bd87416759c820a3f7d05c1a077bbf6\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31527 sha256=277d9d26be4d1d57bdc9c97f7586665c04a22affbb14efaea6d07f236228e289\n",
            "  Stored in directory: /root/.cache/pip/wheels/7c/96/04/4f5f31ff812f684f69f40cb1634357812220aac58d4698048c\n",
            "Successfully built fvcore grad-cam iopath\n",
            "Installing collected packages: yacs, urllib3, ttach, portalocker, idna, fire, chardet, requests, iopath, fvcore, torchattacks, medmnist, grad-cam\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.11\n",
            "    Uninstalling idna-3.11:\n",
            "      Successfully uninstalled idna-3.11\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.25.1 which is incompatible.\n",
            "sphinx 8.2.3 requires requests>=2.30.0, but you have requests 2.25.1 which is incompatible.\n",
            "bigframes 2.28.0 requires requests>=2.27.1, but you have requests 2.25.1 which is incompatible.\n",
            "yfinance 0.2.66 requires requests>=2.31, but you have requests 2.25.1 which is incompatible.\n",
            "tweepy 4.16.0 requires requests<3,>=2.27.0, but you have requests 2.25.1 which is incompatible.\n",
            "google-adk 1.17.0 requires requests<3.0.0,>=2.32.4, but you have requests 2.25.1 which is incompatible.\n",
            "google-genai 1.49.0 requires requests<3.0.0,>=2.28.1, but you have requests 2.25.1 which is incompatible.\n",
            "datasets 4.0.0 requires requests>=2.32.2, but you have requests 2.25.1 which is incompatible.\n",
            "tiktoken 0.12.0 requires requests>=2.26.0, but you have requests 2.25.1 which is incompatible.\n",
            "libpysal 4.13.0 requires requests>=2.27, but you have requests 2.25.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed chardet-4.0.0 fire-0.7.1 fvcore-0.1.5.post20221221 grad-cam-1.5.5 idna-2.10 iopath-0.1.10 medmnist-3.0.2 portalocker-3.2.0 requests-2.25.1 torchattacks-3.5.1 ttach-0.0.3 urllib3-1.26.20 yacs-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --model_name 'resnet50' --dataset 'breastmnist' --pretrained False --epochs 20"
      ],
      "metadata": {
        "id": "P5HPMa32RI0n",
        "outputId": "2af70050-249a-4b84-fa49-4d120e808db1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "/usr/local/lib/python3.12/dist-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
            "Using cuda:0 device.\n",
            "Number of channels:  1\n",
            "Number of classes:  2\n",
            "Using downloaded and verified file: ./data/breastmnist_224.npz\n",
            "Using downloaded and verified file: ./data/breastmnist_224.npz\n",
            "Dataset BreastMNIST of size 224 (breastmnist_224)\n",
            "    Number of datapoints: 546\n",
            "    Root location: ./data\n",
            "    Split: train\n",
            "    Task: binary-class\n",
            "    Number of channels: 1\n",
            "    Meaning of labels: {'0': 'malignant', '1': 'normal, benign'}\n",
            "    Number of samples: {'train': 546, 'val': 78, 'test': 156}\n",
            "    Description: The BreastMNIST is based on a dataset of 780 breast ultrasound images. It is categorized into 3 classes: normal, benign, and malignant. As we use low-resolution images, we simplify the task into binary classification by combining normal and benign as positive and classifying them against malignant as negative. We split the source dataset with a ratio of 7:1:2 into training, validation and test set. The source images of 1×500×500 are resized into 1×28×28.\n",
            "    License: CC BY 4.0\n",
            "===================\n",
            "Dataset BreastMNIST of size 224 (breastmnist_224)\n",
            "    Number of datapoints: 156\n",
            "    Root location: ./data\n",
            "    Split: test\n",
            "    Task: binary-class\n",
            "    Number of channels: 1\n",
            "    Meaning of labels: {'0': 'malignant', '1': 'normal, benign'}\n",
            "    Number of samples: {'train': 546, 'val': 78, 'test': 156}\n",
            "    Description: The BreastMNIST is based on a dataset of 780 breast ultrasound images. It is categorized into 3 classes: normal, benign, and malignant. As we use low-resolution images, we simplify the task into binary classification by combining normal and benign as positive and classifying them against malignant as negative. We split the source dataset with a ratio of 7:1:2 into training, validation and test set. The source images of 1×500×500 are resized into 1×28×28.\n",
            "    License: CC BY 4.0\n",
            "train epoch[1/20] loss:0.495: 100% 23/23 [00:12<00:00,  1.91it/s]\n",
            "100% 4/4 [00:00<00:00,  5.74it/s]\n",
            "[epoch 1] train_loss: 0.590  auc: 0.593  acc: 0.718\n",
            "\n",
            "Saving checkpoint...\n",
            "train epoch[2/20] loss:0.532: 100% 23/23 [00:11<00:00,  1.95it/s]\n",
            "100% 4/4 [00:00<00:00,  6.28it/s]\n",
            "[epoch 2] train_loss: 0.547  auc: 0.724  acc: 0.731\n",
            "\n",
            "Saving checkpoint...\n",
            "train epoch[3/20] loss:0.736: 100% 23/23 [00:12<00:00,  1.91it/s]\n",
            "100% 4/4 [00:00<00:00,  6.74it/s]\n",
            "[epoch 3] train_loss: 0.566  auc: 0.723  acc: 0.731\n",
            "train epoch[4/20] loss:0.496: 100% 23/23 [00:11<00:00,  1.95it/s]\n",
            "100% 4/4 [00:00<00:00,  6.99it/s]\n",
            "[epoch 4] train_loss: 0.558  auc: 0.750  acc: 0.737\n",
            "\n",
            "Saving checkpoint...\n",
            "train epoch[5/20] loss:0.913: 100% 23/23 [00:12<00:00,  1.85it/s]\n",
            "100% 4/4 [00:00<00:00,  6.91it/s]\n",
            "[epoch 5] train_loss: 0.536  auc: 0.778  acc: 0.731\n",
            "\n",
            "Saving checkpoint...\n",
            "train epoch[6/20] loss:0.767: 100% 23/23 [00:12<00:00,  1.86it/s]\n",
            "100% 4/4 [00:00<00:00,  6.67it/s]\n",
            "[epoch 6] train_loss: 0.524  auc: 0.768  acc: 0.763\n",
            "train epoch[7/20] loss:0.589: 100% 23/23 [00:11<00:00,  1.99it/s]\n",
            "100% 4/4 [00:00<00:00,  6.62it/s]\n",
            "[epoch 7] train_loss: 0.547  auc: 0.739  acc: 0.731\n",
            "train epoch[8/20] loss:0.632: 100% 23/23 [00:11<00:00,  1.96it/s]\n",
            "100% 4/4 [00:00<00:00,  6.67it/s]\n",
            "[epoch 8] train_loss: 0.542  auc: 0.728  acc: 0.750\n",
            "train epoch[9/20] loss:0.623: 100% 23/23 [00:12<00:00,  1.77it/s]\n",
            "100% 4/4 [00:00<00:00,  6.59it/s]\n",
            "[epoch 9] train_loss: 0.530  auc: 0.718  acc: 0.731\n",
            "train epoch[10/20] loss:0.535: 100% 23/23 [00:11<00:00,  1.97it/s]\n",
            "100% 4/4 [00:00<00:00,  6.77it/s]\n",
            "[epoch 10] train_loss: 0.531  auc: 0.726  acc: 0.750\n",
            "train epoch[11/20] loss:0.512: 100% 23/23 [00:11<00:00,  1.99it/s]\n",
            "100% 4/4 [00:00<00:00,  6.70it/s]\n",
            "[epoch 11] train_loss: 0.499  auc: 0.756  acc: 0.776\n",
            "train epoch[12/20] loss:0.758: 100% 23/23 [00:11<00:00,  1.96it/s]\n",
            "100% 4/4 [00:00<00:00,  6.68it/s]\n",
            "[epoch 12] train_loss: 0.510  auc: 0.761  acc: 0.808\n",
            "train epoch[13/20] loss:0.591: 100% 23/23 [00:11<00:00,  1.95it/s]\n",
            "100% 4/4 [00:00<00:00,  6.77it/s]\n",
            "[epoch 13] train_loss: 0.514  auc: 0.732  acc: 0.744\n",
            "train epoch[14/20] loss:0.323: 100% 23/23 [00:11<00:00,  1.96it/s]\n",
            "100% 4/4 [00:00<00:00,  6.71it/s]\n",
            "[epoch 14] train_loss: 0.519  auc: 0.766  acc: 0.808\n",
            "train epoch[15/20] loss:0.477: 100% 23/23 [00:11<00:00,  1.92it/s]\n",
            "100% 4/4 [00:00<00:00,  6.61it/s]\n",
            "[epoch 15] train_loss: 0.508  auc: 0.762  acc: 0.827\n",
            "train epoch[16/20] loss:0.531: 100% 23/23 [00:11<00:00,  1.93it/s]\n",
            "100% 4/4 [00:00<00:00,  6.67it/s]\n",
            "[epoch 16] train_loss: 0.530  auc: 0.773  acc: 0.788\n",
            "train epoch[17/20] loss:0.505: 100% 23/23 [00:11<00:00,  1.97it/s]\n",
            "100% 4/4 [00:00<00:00,  6.71it/s]\n",
            "[epoch 17] train_loss: 0.484  auc: 0.768  acc: 0.821\n",
            "train epoch[18/20] loss:0.453: 100% 23/23 [00:11<00:00,  1.95it/s]\n",
            "100% 4/4 [00:00<00:00,  6.54it/s]\n",
            "[epoch 18] train_loss: 0.505  auc: 0.771  acc: 0.795\n",
            "train epoch[19/20] loss:0.423: 100% 23/23 [00:11<00:00,  1.96it/s]\n",
            "100% 4/4 [00:00<00:00,  6.64it/s]\n",
            "[epoch 19] train_loss: 0.508  auc: 0.775  acc: 0.788\n",
            "train epoch[20/20] loss:0.460: 100% 23/23 [00:11<00:00,  1.98it/s]\n",
            "100% 4/4 [00:00<00:00,  6.67it/s]\n",
            "[epoch 20] train_loss: 0.518  auc: 0.776  acc: 0.808\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --model_name 'convnext_tiny' --dataset 'breastmnist' --pretrained False --epochs 20"
      ],
      "metadata": {
        "id": "E_DsfBSb2kKi",
        "outputId": "f5a67e77-b692-41fe-8487-1a000f505930",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "/usr/local/lib/python3.12/dist-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
            "Using cuda:0 device.\n",
            "Number of channels:  1\n",
            "Number of classes:  2\n",
            "Using downloaded and verified file: ./data/breastmnist_224.npz\n",
            "Using downloaded and verified file: ./data/breastmnist_224.npz\n",
            "Dataset BreastMNIST of size 224 (breastmnist_224)\n",
            "    Number of datapoints: 546\n",
            "    Root location: ./data\n",
            "    Split: train\n",
            "    Task: binary-class\n",
            "    Number of channels: 1\n",
            "    Meaning of labels: {'0': 'malignant', '1': 'normal, benign'}\n",
            "    Number of samples: {'train': 546, 'val': 78, 'test': 156}\n",
            "    Description: The BreastMNIST is based on a dataset of 780 breast ultrasound images. It is categorized into 3 classes: normal, benign, and malignant. As we use low-resolution images, we simplify the task into binary classification by combining normal and benign as positive and classifying them against malignant as negative. We split the source dataset with a ratio of 7:1:2 into training, validation and test set. The source images of 1×500×500 are resized into 1×28×28.\n",
            "    License: CC BY 4.0\n",
            "===================\n",
            "Dataset BreastMNIST of size 224 (breastmnist_224)\n",
            "    Number of datapoints: 156\n",
            "    Root location: ./data\n",
            "    Split: test\n",
            "    Task: binary-class\n",
            "    Number of channels: 1\n",
            "    Meaning of labels: {'0': 'malignant', '1': 'normal, benign'}\n",
            "    Number of samples: {'train': 546, 'val': 78, 'test': 156}\n",
            "    Description: The BreastMNIST is based on a dataset of 780 breast ultrasound images. It is categorized into 3 classes: normal, benign, and malignant. As we use low-resolution images, we simplify the task into binary classification by combining normal and benign as positive and classifying them against malignant as negative. We split the source dataset with a ratio of 7:1:2 into training, validation and test set. The source images of 1×500×500 are resized into 1×28×28.\n",
            "    License: CC BY 4.0\n",
            "train epoch[1/20] loss:0.450: 100% 23/23 [00:18<00:00,  1.27it/s]\n",
            "100% 4/4 [00:00<00:00,  5.31it/s]\n",
            "[epoch 1] train_loss: 0.795  auc: 0.468  acc: 0.718\n",
            "\n",
            "Saving checkpoint...\n",
            "train epoch[2/20] loss:0.514: 100% 23/23 [00:18<00:00,  1.28it/s]\n",
            "100% 4/4 [00:00<00:00,  5.39it/s]\n",
            "[epoch 2] train_loss: 0.638  auc: 0.489  acc: 0.712\n",
            "\n",
            "Saving checkpoint...\n",
            "train epoch[3/20] loss:0.532: 100% 23/23 [00:18<00:00,  1.27it/s]\n",
            "100% 4/4 [00:00<00:00,  5.52it/s]\n",
            "[epoch 3] train_loss: 0.600  auc: 0.465  acc: 0.577\n",
            "train epoch[4/20] loss:0.740: 100% 23/23 [00:17<00:00,  1.28it/s]\n",
            "100% 4/4 [00:00<00:00,  5.09it/s]\n",
            "[epoch 4] train_loss: 0.644  auc: 0.471  acc: 0.731\n",
            "train epoch[5/20] loss:0.544: 100% 23/23 [00:17<00:00,  1.31it/s]\n",
            "100% 4/4 [00:00<00:00,  5.47it/s]\n",
            "[epoch 5] train_loss: 0.592  auc: 0.578  acc: 0.731\n",
            "\n",
            "Saving checkpoint...\n",
            "train epoch[6/20] loss:0.592: 100% 23/23 [00:17<00:00,  1.30it/s]\n",
            "100% 4/4 [00:00<00:00,  5.38it/s]\n",
            "[epoch 6] train_loss: 0.585  auc: 0.621  acc: 0.731\n",
            "\n",
            "Saving checkpoint...\n",
            "train epoch[7/20] loss:0.601: 100% 23/23 [00:17<00:00,  1.28it/s]\n",
            "100% 4/4 [00:00<00:00,  5.38it/s]\n",
            "[epoch 7] train_loss: 0.570  auc: 0.669  acc: 0.731\n",
            "\n",
            "Saving checkpoint...\n",
            "train epoch[8/20] loss:0.576: 100% 23/23 [00:18<00:00,  1.27it/s]\n",
            "100% 4/4 [00:00<00:00,  5.48it/s]\n",
            "[epoch 8] train_loss: 0.596  auc: 0.675  acc: 0.731\n",
            "\n",
            "Saving checkpoint...\n",
            "train epoch[9/20] loss:0.565: 100% 23/23 [00:17<00:00,  1.29it/s]\n",
            "100% 4/4 [00:00<00:00,  4.95it/s]\n",
            "[epoch 9] train_loss: 0.566  auc: 0.712  acc: 0.744\n",
            "\n",
            "Saving checkpoint...\n",
            "train epoch[10/20] loss:0.876: 100% 23/23 [00:18<00:00,  1.27it/s]\n",
            "100% 4/4 [00:00<00:00,  5.39it/s]\n",
            "[epoch 10] train_loss: 0.577  auc: 0.701  acc: 0.737\n",
            "train epoch[11/20] loss:0.656: 100% 23/23 [00:18<00:00,  1.26it/s]\n",
            "100% 4/4 [00:00<00:00,  5.41it/s]\n",
            "[epoch 11] train_loss: 0.575  auc: 0.722  acc: 0.750\n",
            "\n",
            "Saving checkpoint...\n",
            "train epoch[12/20] loss:0.574: 100% 23/23 [00:18<00:00,  1.26it/s]\n",
            "100% 4/4 [00:00<00:00,  5.23it/s]\n",
            "[epoch 12] train_loss: 0.564  auc: 0.707  acc: 0.750\n",
            "train epoch[13/20] loss:0.449: 100% 23/23 [00:17<00:00,  1.30it/s]\n",
            "100% 4/4 [00:00<00:00,  5.35it/s]\n",
            "[epoch 13] train_loss: 0.568  auc: 0.718  acc: 0.731\n",
            "train epoch[14/20] loss:0.454: 100% 23/23 [00:17<00:00,  1.30it/s]\n",
            "100% 4/4 [00:00<00:00,  5.58it/s]\n",
            "[epoch 14] train_loss: 0.573  auc: 0.683  acc: 0.737\n",
            "train epoch[15/20] loss:0.664: 100% 23/23 [00:17<00:00,  1.29it/s]\n",
            "100% 4/4 [00:00<00:00,  5.54it/s]\n",
            "[epoch 15] train_loss: 0.555  auc: 0.720  acc: 0.731\n",
            "train epoch[16/20] loss:0.502: 100% 23/23 [00:18<00:00,  1.27it/s]\n",
            "100% 4/4 [00:00<00:00,  5.58it/s]\n",
            "[epoch 16] train_loss: 0.545  auc: 0.693  acc: 0.744\n",
            "train epoch[17/20] loss:0.626: 100% 23/23 [00:17<00:00,  1.30it/s]\n",
            "100% 4/4 [00:00<00:00,  5.49it/s]\n",
            "[epoch 17] train_loss: 0.570  auc: 0.703  acc: 0.737\n",
            "train epoch[18/20] loss:0.664: 100% 23/23 [00:18<00:00,  1.27it/s]\n",
            "100% 4/4 [00:00<00:00,  5.58it/s]\n",
            "[epoch 18] train_loss: 0.560  auc: 0.710  acc: 0.737\n",
            "train epoch[19/20] loss:0.597: 100% 23/23 [00:17<00:00,  1.29it/s]\n",
            "100% 4/4 [00:00<00:00,  5.47it/s]\n",
            "[epoch 19] train_loss: 0.549  auc: 0.701  acc: 0.737\n",
            "train epoch[20/20] loss:0.871: 100% 23/23 [00:18<00:00,  1.28it/s]\n",
            "100% 4/4 [00:00<00:00,  5.55it/s]\n",
            "[epoch 20] train_loss: 0.552  auc: 0.702  acc: 0.744\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --model_name 'vit_small_patch8_224' --dataset 'breastmnist' --pretrained False --epochs 20"
      ],
      "metadata": {
        "id": "MPTXfwZ53Yx4",
        "outputId": "f1f4b78c-bc40-4f5f-ddac-e86518a6f4bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "/usr/local/lib/python3.12/dist-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
            "Using cuda:0 device.\n",
            "Number of channels:  1\n",
            "Number of classes:  2\n",
            "Using downloaded and verified file: ./data/breastmnist_224.npz\n",
            "Using downloaded and verified file: ./data/breastmnist_224.npz\n",
            "Dataset BreastMNIST of size 224 (breastmnist_224)\n",
            "    Number of datapoints: 546\n",
            "    Root location: ./data\n",
            "    Split: train\n",
            "    Task: binary-class\n",
            "    Number of channels: 1\n",
            "    Meaning of labels: {'0': 'malignant', '1': 'normal, benign'}\n",
            "    Number of samples: {'train': 546, 'val': 78, 'test': 156}\n",
            "    Description: The BreastMNIST is based on a dataset of 780 breast ultrasound images. It is categorized into 3 classes: normal, benign, and malignant. As we use low-resolution images, we simplify the task into binary classification by combining normal and benign as positive and classifying them against malignant as negative. We split the source dataset with a ratio of 7:1:2 into training, validation and test set. The source images of 1×500×500 are resized into 1×28×28.\n",
            "    License: CC BY 4.0\n",
            "===================\n",
            "Dataset BreastMNIST of size 224 (breastmnist_224)\n",
            "    Number of datapoints: 156\n",
            "    Root location: ./data\n",
            "    Split: test\n",
            "    Task: binary-class\n",
            "    Number of channels: 1\n",
            "    Meaning of labels: {'0': 'malignant', '1': 'normal, benign'}\n",
            "    Number of samples: {'train': 546, 'val': 78, 'test': 156}\n",
            "    Description: The BreastMNIST is based on a dataset of 780 breast ultrasound images. It is categorized into 3 classes: normal, benign, and malignant. As we use low-resolution images, we simplify the task into binary classification by combining normal and benign as positive and classifying them against malignant as negative. We split the source dataset with a ratio of 7:1:2 into training, validation and test set. The source images of 1×500×500 are resized into 1×28×28.\n",
            "    License: CC BY 4.0\n",
            "train epoch[1/20] loss:0.528: 100% 23/23 [00:34<00:00,  1.52s/it]\n",
            "100% 4/4 [00:02<00:00,  1.62it/s]\n",
            "[epoch 1] train_loss: 0.773  auc: 0.525  acc: 0.731\n",
            "\n",
            "Saving checkpoint...\n",
            "train epoch[2/20] loss:0.408: 100% 23/23 [00:33<00:00,  1.47s/it]\n",
            "100% 4/4 [00:02<00:00,  1.67it/s]\n",
            "[epoch 2] train_loss: 0.577  auc: 0.541  acc: 0.731\n",
            "\n",
            "Saving checkpoint...\n",
            "train epoch[3/20] loss:0.560: 100% 23/23 [00:34<00:00,  1.48s/it]\n",
            "100% 4/4 [00:02<00:00,  1.67it/s]\n",
            "[epoch 3] train_loss: 0.579  auc: 0.559  acc: 0.731\n",
            "\n",
            "Saving checkpoint...\n",
            "train epoch[4/20] loss:0.648: 100% 23/23 [00:34<00:00,  1.48s/it]\n",
            "100% 4/4 [00:02<00:00,  1.67it/s]\n",
            "[epoch 4] train_loss: 0.577  auc: 0.586  acc: 0.731\n",
            "\n",
            "Saving checkpoint...\n",
            "train epoch[5/20] loss:0.541: 100% 23/23 [00:33<00:00,  1.48s/it]\n",
            "100% 4/4 [00:02<00:00,  1.67it/s]\n",
            "[epoch 5] train_loss: 0.574  auc: 0.626  acc: 0.731\n",
            "\n",
            "Saving checkpoint...\n",
            "train epoch[6/20] loss:0.609: 100% 23/23 [00:34<00:00,  1.48s/it]\n",
            "100% 4/4 [00:02<00:00,  1.67it/s]\n",
            "[epoch 6] train_loss: 0.570  auc: 0.626  acc: 0.731\n",
            "\n",
            "Saving checkpoint...\n",
            "train epoch[7/20] loss:0.544: 100% 23/23 [00:34<00:00,  1.48s/it]\n",
            "100% 4/4 [00:02<00:00,  1.67it/s]\n",
            "[epoch 7] train_loss: 0.576  auc: 0.683  acc: 0.731\n",
            "\n",
            "Saving checkpoint...\n",
            "train epoch[8/20] loss:0.502: 100% 23/23 [00:33<00:00,  1.47s/it]\n",
            "100% 4/4 [00:02<00:00,  1.66it/s]\n",
            "[epoch 8] train_loss: 0.559  auc: 0.695  acc: 0.724\n",
            "\n",
            "Saving checkpoint...\n",
            "train epoch[9/20] loss:0.385: 100% 23/23 [00:34<00:00,  1.49s/it]\n",
            "100% 4/4 [00:02<00:00,  1.66it/s]\n",
            "[epoch 9] train_loss: 0.551  auc: 0.734  acc: 0.731\n",
            "\n",
            "Saving checkpoint...\n",
            "train epoch[10/20] loss:0.859: 100% 23/23 [00:33<00:00,  1.48s/it]\n",
            "100% 4/4 [00:02<00:00,  1.66it/s]\n",
            "[epoch 10] train_loss: 0.560  auc: 0.763  acc: 0.724\n",
            "\n",
            "Saving checkpoint...\n",
            "train epoch[11/20] loss:0.612: 100% 23/23 [00:33<00:00,  1.47s/it]\n",
            "100% 4/4 [00:02<00:00,  1.65it/s]\n",
            "[epoch 11] train_loss: 0.510  auc: 0.784  acc: 0.795\n",
            "\n",
            "Saving checkpoint...\n",
            "train epoch[12/20] loss:0.510: 100% 23/23 [00:34<00:00,  1.48s/it]\n",
            "100% 4/4 [00:02<00:00,  1.65it/s]\n",
            "[epoch 12] train_loss: 0.526  auc: 0.779  acc: 0.756\n",
            "train epoch[13/20] loss:0.466: 100% 23/23 [00:33<00:00,  1.48s/it]\n",
            "100% 4/4 [00:02<00:00,  1.66it/s]\n",
            "[epoch 13] train_loss: 0.507  auc: 0.780  acc: 0.763\n",
            "train epoch[14/20] loss:0.516: 100% 23/23 [00:33<00:00,  1.47s/it]\n",
            "100% 4/4 [00:02<00:00,  1.67it/s]\n",
            "[epoch 14] train_loss: 0.517  auc: 0.777  acc: 0.756\n",
            "train epoch[15/20] loss:0.514: 100% 23/23 [00:33<00:00,  1.47s/it]\n",
            "100% 4/4 [00:02<00:00,  1.67it/s]\n",
            "[epoch 15] train_loss: 0.518  auc: 0.783  acc: 0.756\n",
            "train epoch[16/20] loss:0.650: 100% 23/23 [00:33<00:00,  1.47s/it]\n",
            "100% 4/4 [00:02<00:00,  1.67it/s]\n",
            "[epoch 16] train_loss: 0.511  auc: 0.781  acc: 0.763\n",
            "train epoch[17/20] loss:0.376: 100% 23/23 [00:33<00:00,  1.47s/it]\n",
            "100% 4/4 [00:02<00:00,  1.67it/s]\n",
            "[epoch 17] train_loss: 0.499  auc: 0.784  acc: 0.756\n",
            "train epoch[18/20] loss:0.647: 100% 23/23 [00:33<00:00,  1.48s/it]\n",
            "100% 4/4 [00:02<00:00,  1.68it/s]\n",
            "[epoch 18] train_loss: 0.520  auc: 0.781  acc: 0.756\n",
            "train epoch[19/20] loss:0.334: 100% 23/23 [00:33<00:00,  1.47s/it]\n",
            "100% 4/4 [00:02<00:00,  1.67it/s]\n",
            "[epoch 19] train_loss: 0.506  auc: 0.781  acc: 0.750\n",
            "train epoch[20/20] loss:0.516: 100% 23/23 [00:34<00:00,  1.49s/it]\n",
            "100% 4/4 [00:02<00:00,  1.67it/s]\n",
            "[epoch 20] train_loss: 0.496  auc: 0.784  acc: 0.763\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --model_name 'nextvit_small' --dataset 'breastmnist' --pretrained False --epochs 20"
      ],
      "metadata": {
        "id": "xEPFBkpb3sgh",
        "outputId": "d88e1712-80cf-4d55-b60a-c9df78c4fca9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "/usr/local/lib/python3.12/dist-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
            "Using cuda:0 device.\n",
            "Number of channels:  1\n",
            "Number of classes:  2\n",
            "Using downloaded and verified file: ./data/breastmnist_224.npz\n",
            "Using downloaded and verified file: ./data/breastmnist_224.npz\n",
            "Dataset BreastMNIST of size 224 (breastmnist_224)\n",
            "    Number of datapoints: 546\n",
            "    Root location: ./data\n",
            "    Split: train\n",
            "    Task: binary-class\n",
            "    Number of channels: 1\n",
            "    Meaning of labels: {'0': 'malignant', '1': 'normal, benign'}\n",
            "    Number of samples: {'train': 546, 'val': 78, 'test': 156}\n",
            "    Description: The BreastMNIST is based on a dataset of 780 breast ultrasound images. It is categorized into 3 classes: normal, benign, and malignant. As we use low-resolution images, we simplify the task into binary classification by combining normal and benign as positive and classifying them against malignant as negative. We split the source dataset with a ratio of 7:1:2 into training, validation and test set. The source images of 1×500×500 are resized into 1×28×28.\n",
            "    License: CC BY 4.0\n",
            "===================\n",
            "Dataset BreastMNIST of size 224 (breastmnist_224)\n",
            "    Number of datapoints: 156\n",
            "    Root location: ./data\n",
            "    Split: test\n",
            "    Task: binary-class\n",
            "    Number of channels: 1\n",
            "    Meaning of labels: {'0': 'malignant', '1': 'normal, benign'}\n",
            "    Number of samples: {'train': 546, 'val': 78, 'test': 156}\n",
            "    Description: The BreastMNIST is based on a dataset of 780 breast ultrasound images. It is categorized into 3 classes: normal, benign, and malignant. As we use low-resolution images, we simplify the task into binary classification by combining normal and benign as positive and classifying them against malignant as negative. We split the source dataset with a ratio of 7:1:2 into training, validation and test set. The source images of 1×500×500 are resized into 1×28×28.\n",
            "    License: CC BY 4.0\n",
            "train epoch[1/20] loss:0.742: 100% 23/23 [00:16<00:00,  1.40it/s]\n",
            "100% 4/4 [00:01<00:00,  2.72it/s]\n",
            "[epoch 1] train_loss: 0.779  auc: 0.440  acc: 0.731\n",
            "\n",
            "Saving checkpoint...\n",
            "train epoch[2/20] loss:0.859: 100% 23/23 [00:16<00:00,  1.40it/s]\n",
            "100% 4/4 [00:01<00:00,  3.17it/s]\n",
            "[epoch 2] train_loss: 0.694  auc: 0.632  acc: 0.269\n",
            "\n",
            "Saving checkpoint...\n",
            "train epoch[3/20] loss:0.716: 100% 23/23 [00:16<00:00,  1.36it/s]\n",
            "100% 4/4 [00:01<00:00,  3.17it/s]\n",
            "[epoch 3] train_loss: 0.644  auc: 0.552  acc: 0.724\n",
            "train epoch[4/20] loss:0.544: 100% 23/23 [00:16<00:00,  1.42it/s]\n",
            "100% 4/4 [00:01<00:00,  3.18it/s]\n",
            "[epoch 4] train_loss: 0.656  auc: 0.799  acc: 0.718\n",
            "\n",
            "Saving checkpoint...\n",
            "train epoch[5/20] loss:0.595: 100% 23/23 [00:16<00:00,  1.39it/s]\n",
            "100% 4/4 [00:01<00:00,  3.21it/s]\n",
            "[epoch 5] train_loss: 0.602  auc: 0.781  acc: 0.615\n",
            "train epoch[6/20] loss:0.658: 100% 23/23 [00:16<00:00,  1.40it/s]\n",
            "100% 4/4 [00:01<00:00,  3.20it/s]\n",
            "[epoch 6] train_loss: 0.610  auc: 0.727  acc: 0.737\n",
            "train epoch[7/20] loss:0.445: 100% 23/23 [00:16<00:00,  1.37it/s]\n",
            "100% 4/4 [00:01<00:00,  3.15it/s]\n",
            "[epoch 7] train_loss: 0.597  auc: 0.678  acc: 0.667\n",
            "train epoch[8/20] loss:0.516: 100% 23/23 [00:16<00:00,  1.40it/s]\n",
            "100% 4/4 [00:01<00:00,  3.18it/s]\n",
            "[epoch 8] train_loss: 0.562  auc: 0.762  acc: 0.327\n",
            "train epoch[9/20] loss:0.459: 100% 23/23 [00:16<00:00,  1.39it/s]\n",
            "100% 4/4 [00:01<00:00,  3.08it/s]\n",
            "[epoch 9] train_loss: 0.544  auc: 0.798  acc: 0.731\n",
            "train epoch[10/20] loss:0.616: 100% 23/23 [00:16<00:00,  1.41it/s]\n",
            "100% 4/4 [00:01<00:00,  3.21it/s]\n",
            "[epoch 10] train_loss: 0.549  auc: 0.834  acc: 0.750\n",
            "\n",
            "Saving checkpoint...\n",
            "train epoch[11/20] loss:0.562: 100% 23/23 [00:16<00:00,  1.40it/s]\n",
            "100% 4/4 [00:01<00:00,  3.18it/s]\n",
            "[epoch 11] train_loss: 0.540  auc: 0.825  acc: 0.808\n",
            "train epoch[12/20] loss:0.473: 100% 23/23 [00:16<00:00,  1.38it/s]\n",
            "100% 4/4 [00:01<00:00,  3.09it/s]\n",
            "[epoch 12] train_loss: 0.546  auc: 0.876  acc: 0.833\n",
            "\n",
            "Saving checkpoint...\n",
            "train epoch[13/20] loss:0.688: 100% 23/23 [00:16<00:00,  1.40it/s]\n",
            "100% 4/4 [00:01<00:00,  3.23it/s]\n",
            "[epoch 13] train_loss: 0.521  auc: 0.841  acc: 0.795\n",
            "train epoch[14/20] loss:0.494: 100% 23/23 [00:16<00:00,  1.41it/s]\n",
            "100% 4/4 [00:01<00:00,  3.09it/s]\n",
            "[epoch 14] train_loss: 0.517  auc: 0.870  acc: 0.840\n",
            "train epoch[15/20] loss:0.647: 100% 23/23 [00:16<00:00,  1.39it/s]\n",
            "100% 4/4 [00:01<00:00,  3.23it/s]\n",
            "[epoch 15] train_loss: 0.501  auc: 0.860  acc: 0.833\n",
            "train epoch[16/20] loss:0.565: 100% 23/23 [00:16<00:00,  1.40it/s]\n",
            "100% 4/4 [00:01<00:00,  3.07it/s]\n",
            "[epoch 16] train_loss: 0.509  auc: 0.873  acc: 0.821\n",
            "train epoch[17/20] loss:0.410: 100% 23/23 [00:16<00:00,  1.40it/s]\n",
            "100% 4/4 [00:01<00:00,  3.20it/s]\n",
            "[epoch 17] train_loss: 0.494  auc: 0.877  acc: 0.821\n",
            "\n",
            "Saving checkpoint...\n",
            "train epoch[18/20] loss:0.354: 100% 23/23 [00:16<00:00,  1.41it/s]\n",
            "100% 4/4 [00:01<00:00,  3.19it/s]\n",
            "[epoch 18] train_loss: 0.500  auc: 0.877  acc: 0.776\n",
            "train epoch[19/20] loss:0.721: 100% 23/23 [00:16<00:00,  1.39it/s]\n",
            "100% 4/4 [00:01<00:00,  3.09it/s]\n",
            "[epoch 19] train_loss: 0.504  auc: 0.881  acc: 0.808\n",
            "\n",
            "Saving checkpoint...\n",
            "train epoch[20/20] loss:0.419: 100% 23/23 [00:16<00:00,  1.39it/s]\n",
            "100% 4/4 [00:01<00:00,  3.21it/s]\n",
            "[epoch 20] train_loss: 0.486  auc: 0.878  acc: 0.801\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --model_name 'Hybridmamba' --dataset 'breastmnist' --pretrained False --epochs 20"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9cmo4lhHQqs",
        "outputId": "19ff2728-1c36-4c93-cbe7-096654dde241"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "/usr/local/lib/python3.12/dist-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
            "Using cuda:0 device.\n",
            "Number of channels:  1\n",
            "Number of classes:  2\n",
            "Using downloaded and verified file: ./data/breastmnist_224.npz\n",
            "Using downloaded and verified file: ./data/breastmnist_224.npz\n",
            "initialize_weights...\n",
            "Downloading checkpoint from https://dl.dropbox.com/scl/fi/6nnec8hxcn5da6vov7h2a/MedViT_small.pth?rlkey=yf5twra1cv6ep2oqr79tbzyg5&st=rwx5hy8z&dl=0...\n",
            "Checkpoint downloaded and saved to ./MedViT_small.pth\n",
            "/content/MedViTV2/main.py:271: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(checkpoint_path)\n",
            "Dataset BreastMNIST of size 224 (breastmnist_224)\n",
            "    Number of datapoints: 546\n",
            "    Root location: ./data\n",
            "    Split: train\n",
            "    Task: binary-class\n",
            "    Number of channels: 1\n",
            "    Meaning of labels: {'0': 'malignant', '1': 'normal, benign'}\n",
            "    Number of samples: {'train': 546, 'val': 78, 'test': 156}\n",
            "    Description: The BreastMNIST is based on a dataset of 780 breast ultrasound images. It is categorized into 3 classes: normal, benign, and malignant. As we use low-resolution images, we simplify the task into binary classification by combining normal and benign as positive and classifying them against malignant as negative. We split the source dataset with a ratio of 7:1:2 into training, validation and test set. The source images of 1×500×500 are resized into 1×28×28.\n",
            "    License: CC BY 4.0\n",
            "===================\n",
            "Dataset BreastMNIST of size 224 (breastmnist_224)\n",
            "    Number of datapoints: 156\n",
            "    Root location: ./data\n",
            "    Split: test\n",
            "    Task: binary-class\n",
            "    Number of channels: 1\n",
            "    Meaning of labels: {'0': 'malignant', '1': 'normal, benign'}\n",
            "    Number of samples: {'train': 546, 'val': 78, 'test': 156}\n",
            "    Description: The BreastMNIST is based on a dataset of 780 breast ultrasound images. It is categorized into 3 classes: normal, benign, and malignant. As we use low-resolution images, we simplify the task into binary classification by combining normal and benign as positive and classifying them against malignant as negative. We split the source dataset with a ratio of 7:1:2 into training, validation and test set. The source images of 1×500×500 are resized into 1×28×28.\n",
            "    License: CC BY 4.0\n",
            "train epoch[1/20] loss:0.680: 100% 23/23 [00:16<00:00,  1.36it/s]\n",
            "100% 4/4 [00:01<00:00,  3.80it/s]\n",
            "[epoch 1] train_loss: 0.679  auc: 0.488  acc: 0.731\n",
            "\n",
            "Saving checkpoint...\n",
            "train epoch[2/20] loss:0.650: 100% 23/23 [00:17<00:00,  1.34it/s]\n",
            "100% 4/4 [00:01<00:00,  3.89it/s]\n",
            "[epoch 2] train_loss: 0.674  auc: 0.416  acc: 0.699\n",
            "train epoch[3/20] loss:0.747: 100% 23/23 [00:17<00:00,  1.34it/s]\n",
            "100% 4/4 [00:01<00:00,  3.81it/s]\n",
            "[epoch 3] train_loss: 0.664  auc: 0.635  acc: 0.750\n",
            "\n",
            "Saving checkpoint...\n",
            "train epoch[4/20] loss:0.629: 100% 23/23 [00:17<00:00,  1.34it/s]\n",
            "100% 4/4 [00:01<00:00,  3.73it/s]\n",
            "[epoch 4] train_loss: 0.649  auc: 0.699  acc: 0.603\n",
            "\n",
            "Saving checkpoint...\n",
            "train epoch[5/20] loss:0.583: 100% 23/23 [00:17<00:00,  1.34it/s]\n",
            "100% 4/4 [00:01<00:00,  3.69it/s]\n",
            "[epoch 5] train_loss: 0.627  auc: 0.758  acc: 0.769\n",
            "\n",
            "Saving checkpoint...\n",
            "train epoch[6/20] loss:0.515: 100% 23/23 [00:17<00:00,  1.34it/s]\n",
            "100% 4/4 [00:01<00:00,  3.85it/s]\n",
            "[epoch 6] train_loss: 0.632  auc: 0.693  acc: 0.673\n",
            "train epoch[7/20] loss:0.559: 100% 23/23 [00:16<00:00,  1.36it/s]\n",
            "100% 4/4 [00:01<00:00,  3.59it/s]\n",
            "[epoch 7] train_loss: 0.619  auc: 0.695  acc: 0.750\n",
            "train epoch[8/20] loss:0.506: 100% 23/23 [00:17<00:00,  1.34it/s]\n",
            "100% 4/4 [00:01<00:00,  3.78it/s]\n",
            "[epoch 8] train_loss: 0.603  auc: 0.735  acc: 0.763\n",
            "train epoch[9/20] loss:0.717: 100% 23/23 [00:16<00:00,  1.36it/s]\n",
            "100% 4/4 [00:01<00:00,  3.57it/s]\n",
            "[epoch 9] train_loss: 0.599  auc: 0.699  acc: 0.750\n",
            "train epoch[10/20] loss:0.626: 100% 23/23 [00:17<00:00,  1.33it/s]\n",
            "100% 4/4 [00:01<00:00,  3.79it/s]\n",
            "[epoch 10] train_loss: 0.589  auc: 0.700  acc: 0.705\n",
            "train epoch[11/20] loss:0.504: 100% 23/23 [00:16<00:00,  1.36it/s]\n",
            "100% 4/4 [00:01<00:00,  3.73it/s]\n",
            "[epoch 11] train_loss: 0.590  auc: 0.760  acc: 0.795\n",
            "\n",
            "Saving checkpoint...\n",
            "train epoch[12/20] loss:0.549: 100% 23/23 [00:17<00:00,  1.34it/s]\n",
            "100% 4/4 [00:01<00:00,  3.56it/s]\n",
            "[epoch 12] train_loss: 0.593  auc: 0.768  acc: 0.769\n",
            "\n",
            "Saving checkpoint...\n",
            "train epoch[13/20] loss:0.602: 100% 23/23 [00:17<00:00,  1.34it/s]\n",
            "100% 4/4 [00:01<00:00,  3.77it/s]\n",
            "[epoch 13] train_loss: 0.592  auc: 0.740  acc: 0.583\n",
            "train epoch[14/20] loss:0.615: 100% 23/23 [00:17<00:00,  1.35it/s]\n",
            "100% 4/4 [00:01<00:00,  3.54it/s]\n",
            "[epoch 14] train_loss: 0.578  auc: 0.797  acc: 0.763\n",
            "\n",
            "Saving checkpoint...\n",
            "train epoch[15/20] loss:0.596: 100% 23/23 [00:16<00:00,  1.36it/s]\n",
            "100% 4/4 [00:01<00:00,  3.75it/s]\n",
            "[epoch 15] train_loss: 0.590  auc: 0.811  acc: 0.788\n",
            "\n",
            "Saving checkpoint...\n",
            "train epoch[16/20] loss:0.521: 100% 23/23 [00:17<00:00,  1.32it/s]\n",
            "100% 4/4 [00:01<00:00,  3.76it/s]\n",
            "[epoch 16] train_loss: 0.571  auc: 0.787  acc: 0.782\n",
            "train epoch[17/20] loss:0.529: 100% 23/23 [00:16<00:00,  1.36it/s]\n",
            "100% 4/4 [00:01<00:00,  3.73it/s]\n",
            "[epoch 17] train_loss: 0.572  auc: 0.797  acc: 0.821\n",
            "train epoch[18/20] loss:0.685: 100% 23/23 [00:17<00:00,  1.33it/s]\n",
            "100% 4/4 [00:01<00:00,  3.86it/s]\n",
            "[epoch 18] train_loss: 0.569  auc: 0.807  acc: 0.808\n",
            "train epoch[19/20] loss:0.662: 100% 23/23 [00:16<00:00,  1.36it/s]\n",
            "100% 4/4 [00:01<00:00,  3.87it/s]\n",
            "[epoch 19] train_loss: 0.569  auc: 0.803  acc: 0.827\n",
            "train epoch[20/20] loss:0.517: 100% 23/23 [00:17<00:00,  1.35it/s]\n",
            "100% 4/4 [00:01<00:00,  3.67it/s]\n",
            "[epoch 20] train_loss: 0.567  auc: 0.792  acc: 0.776\n",
            "Finished Training\n"
          ]
        }
      ]
    }
  ]
}